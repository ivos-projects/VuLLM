{
	"causal-1000-balanced": {
		"basemodel": "codellama/CodeLlama-7b-Instruct-hf",
		"adapter_path": "/home/os/vullm/adapters/causal-1000-balanced-01",
		"logdir": "/home/os/vullm/logs",
		"dataset": "test", 
		"balanced": true,
		"max_length": 2048,
		"max_samples": 1000,
		"truncated_train": false,
		"proompt_template": true,
		"run_name": "farbror-laktris",
		"per_device_train_batch_size": 2,
		"gradient_accumulation_steps": 12,
		"warmup_steps": 10,
		"epochs": 10,
		"learning_rate": 0.0002
	},
	"causal-100-balanced": {
		"basemodel": "codellama/CodeLlama-7b-Instruct-hf",
		"adapter_path": "/home/os/vullm/adapters/causal-100-balanced-01",
		"logdir": "/home/os/vullm/logs",
		"dataset": "test", 
		"balanced": true,
		"max_length": 2048,
		"max_samples": 100,
		"truncated_train": false,
		"proompt_template": true,
		"run_name": "hans-goran",
		"per_device_train_batch_size": 2,
		"gradient_accumulation_steps": 12,
		"warmup_steps": 10,
		"epochs": 5,
		"learning_rate": 0.0002
	},
	"zero-shot": {
		"basemodel": "codellama/CodeLlama-7b-Instruct-hf",
		"logdir": "/home/os/vullm/logs",
		"dataset": "sangte-per", 
		"balanced": true,
		"max_length": 2048,
		"max_samples": 100,
		"truncated_train": false,
		"proompt_template": true
	},
	"sequence-balanced": {
		"basemodel": "codellama/CodeLlama-7b-hf",
		"adapter_path": "/home/os/vullm/adapters/sequence/sequence-balanced",
		"logdir": "/home/os/vullm/logs",
		"dataset": "test", 
		"report_to": "wandb",
		"balanced": true,
		"max_length": 2048,
		"max_samples": 100000,
		"max_eval_samples": 500,
		"truncated_train": false,
		"proompt_template": false,
		"run_name": "benght-ake",
		"per_device_train_batch_size": 2,
		"gradient_accumulation_steps": 8,
		"warmup_steps": 10,
		"epochs": 5,
		"learning_rate": 0.0002
	},
	"sequence-unbalanced": {
		"basemodel": "codellama/CodeLlama-7b-hf",
		"adapter_path": "/home/os/vullm/adapters/sequence/sequence-unbalanced",
		"logdir": "/home/os/vullm/logs",
		"dataset": "test", 
		"report_to": "wandb",
		"balanced": false,
		"max_length": 2048,
		"max_samples": 100000,
		"max_eval_samples": 500,
		"truncated_train": false,
		"proompt_template": false,
		"run_name": "hesa-fredrik",
		"per_device_train_batch_size": 2,
		"gradient_accumulation_steps": 8,
		"warmup_steps": 10,
		"epochs": 5,
		"learning_rate": 0.0002
	}

}